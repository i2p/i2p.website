---
title: "性能"
description: "I2P 网络性能：当前表现、历史改进以及未来优化思路"
slug: "performance"
lastUpdated: "2025-10"
accurateFor: "2.10.0"
reviewStatus: "needs-review"
---

## I2P 网络性能：速度、连接和资源管理

I2P 网络是完全动态的。每个客户端都被其他节点所知晓,并在本地测试已知节点的可达性和容量。只有可达且具备足够容量的节点才会被保存到本地 NetDB 中。在隧道构建过程中,会从这个节点池中选择最佳资源来构建隧道。由于测试是持续进行的,节点池会不断变化。每个 I2P 节点都知道 NetDB 的不同部分,这意味着每个 router 都有一组不同的 I2P 节点可用于隧道构建。即使两个 router 拥有相同的已知节点子集,可达性和容量测试也可能显示出不同的结果,因为当一个 router 进行测试时,其他 router 可能正处于负载状态,而当第二个 router 测试时,它们可能又处于空闲状态。

这说明了为什么每个 I2P 节点会选择不同的节点来构建 tunnel。因为每个 I2P 节点都有不同的延迟和带宽,tunnel(通过这些节点构建)具有不同的延迟和带宽值。并且由于每个 I2P 节点构建的 tunnel 不同,没有两个 I2P 节点拥有相同的 tunnel 集合。

服务器/客户端被称为"destination"，每个 destination 至少有一个入站 tunnel 和一个出站 tunnel。默认情况下每个 tunnel 有 3 跳。这意味着一次完整的往返通信（客户端 → 服务器 → 客户端）总共需要 12 跳（经过 12 个不同的 I2P 节点）。

每个数据包会经过 6 个其他 I2P 节点才能到达服务器：

client - hop1 - hop2 - hop3 - hopa1 - hopa2 - hopa3 - server

并且在返回路径上经过 6 个不同的 I2P 节点:

server - hopb1 - hopb2 - hopb3 - hopc1 - hopc2 - hopc3 - client

网络上的流量在发送新数据之前需要一个 ACK；它需要等待服务器返回 ACK：发送数据，等待 ACK，发送更多数据，等待 ACK。由于 RTT (Round Trip Time，往返时间) 累积了这个往返过程中每个 I2P 节点和每个连接的延迟，通常需要 1-3 秒 ACK 才能返回到客户端。由于 TCP 和 I2P 传输设计的原因，数据包的大小是有限的。这些条件综合起来为每个 tunnel 设置了大约 20-50 kB/s 的最大带宽限制。然而，如果 tunnel 中只有一个跳只能分配 5 kB/s 的带宽，那么整个 tunnel 就被限制为 5 kB/s，与延迟和其他限制无关。

加密、延迟以及隧道的构建方式使得建立隧道需要消耗大量 CPU 时间。这就是为什么一个目标节点只允许拥有最多 6 条入站隧道和 6 条出站隧道来传输数据。每条隧道最大速率为 50 kB/s,一个目标节点总共可以使用大约 300 kB/s 的流量(实际上,如果使用较短的隧道且可用匿名性较低或无匿名性,流量可能会更多)。使用中的隧道每 10 分钟会被丢弃,并建立新的隧道。这种隧道更换,以及有时客户端关闭或失去与网络的连接,有时会导致隧道和连接中断。这种情况的一个例子可以在 IRC2P Network 中看到,表现为连接丢失(ping 超时)或使用 eepget 时出现问题。

由于目的地数量有限，且每个目的地的隧道数量有限，一个 I2P 节点仅使用经过其他 I2P 节点的有限数量的隧道。例如，如果一个 I2P 节点是上述小例子中的"hop1"，它只能看到一条源自客户端的参与隧道。如果我们对整个 I2P 网络进行汇总，只有相当有限数量的参与隧道可以用总共有限的带宽来构建。如果将这些有限的数量分配到 I2P 节点的数量上，那么只有一小部分可用带宽/容量可供使用。

为了保持匿名性,整个网络不应该使用单个router来构建隧道。如果一个router充当所有I2P节点的隧道router,它就会成为一个非常现实的单点故障,同时也成为收集客户端IP和数据的中心点。这就是为什么网络在隧道构建过程中会将流量分散到各个节点上。

性能方面的另一个考量是 I2P 处理网状网络的方式。每个逐跳连接在 I2P 节点上使用一个 TCP 或 UDP 连接。当有 1000 个连接时,就会看到 1000 个 TCP 连接。这是相当多的,而一些家用和小型办公室路由器只允许少量连接。I2P 试图将这些连接限制在每种 UDP 和 TCP 类型各 1500 个以下。这也限制了通过 I2P 节点路由的流量。

如果一个节点是可达的，带宽设置为共享 >128 kB/s 并且全天候在线，它应该会在一段时间后被用于参与流量转发。如果中间出现下线，其他节点对该 I2P 节点进行的测试会告知它们该节点不可达。这会在其他节点上阻止该节点至少 24 小时。因此，测试到该节点下线的其他节点将在 24 小时内不会使用该节点来构建 tunnel。这就是为什么在重启/关闭 I2P router 后，你的流量在至少 24 小时内会较低的原因。

此外，其他 I2P 节点需要知道某个 I2P router 才能测试其可达性和容量。当你与网络互动时，例如使用应用程序或访问 I2P 站点，这个过程会变得更快，这将导致更多的 tunnel 构建，从而使网络上的节点有更多的活动和可达性进行测试。

## 性能历史记录（精选）

多年来,I2P 已经实现了许多显著的性能改进:

### Native math

通过 JNI 绑定到 GNU MP 库（GMP）来加速 BigInteger `modPow` 运算，该运算此前占据了主要的 CPU 时间。早期结果显示公钥密码学性能获得了显著提升。参见：/misc/jbigi/

### Garlic wrapping a "reply" LeaseSet (tuned)

以前,回复通常需要在网络数据库中查找发送者的 LeaseSet。在初始 garlic 中捆绑发送者的 LeaseSet 可以改善回复延迟。现在这是有选择性地进行的(连接开始时或当 LeaseSet 发生变化时),以减少开销。

### 原生数学库

在传输握手过程中将一些验证步骤提前,以便更早地拒绝有问题的节点(时钟错误、NAT/防火墙配置不当、版本不兼容),从而节省CPU和带宽资源。

### 对"回复"LeaseSet 进行 Garlic 封装(调优)

使用上下文感知的隧道测试:避免测试已知正在传输数据的隧道;优先在空闲时进行测试。这可以减少开销并加快检测失效隧道的速度。

### 更高效的 TCP 拒绝

为给定连接持久化选择可减少乱序传递，并允许流式传输库增加窗口大小，从而提高吞吐量。

### 隧道测试调整

GZip 或类似压缩方式用于冗长结构(例如 RouterInfo 选项),在适当情况下可减少带宽占用。

### 持久化隧道/租约选择

替代简单的"ministreaming"协议。现代 streaming 包含选择性 ACK 和针对 I2P 匿名、面向消息基础设施量身定制的拥塞控制。参见：/docs/api/streaming/

## Future Performance Improvements (historical ideas)

以下是历史上记录的潜在改进想法。其中许多已经过时、已实现，或已被架构变更所取代。

### 压缩选定的数据结构

改进路由器为隧道构建选择对等节点的方式,以避免选择慢速或过载的节点,同时保持对强大对手发起的女巫攻击(Sybil attacks)的抵抗能力。

### 完整流式协议

当密钥空间稳定时减少不必要的探索;调整查找中返回多少对等节点以及执行多少并发搜索。

### Session Tag tuning and improvements (legacy)

对于传统的 ElGamal/AES+SessionTag 方案,更智能的过期和补充策略可减少 ElGamal 回退和标签浪费。

### 更好的节点分析和选择

从新会话建立期间种子化的同步 PRNG 生成标签,将每条消息开销从预先交付的标签中减少。

### 网络数据库调优

更长的隧道生命周期配合修复机制可以减少重建开销;需要在匿名性和可靠性之间取得平衡。

### Session Tag 调优和改进 (legacy)

更早地拒绝无效的 peer,并使隧道测试更具上下文感知能力,以减少争用和延迟。

### 将 SessionTag 迁移到同步 PRNG(旧版)

选择性 LeaseSet 捆绑、压缩的 RouterInfo 选项以及完整 streaming 协议的采用,共同提升了感知性能。

---


另请参阅：

- [Tunnel Routing（隧道路由）](/docs/overview/tunnel-routing/)
- [Peer Selection（节点选择）](/docs/overview/tunnel-routing/)
- [Transports（传输协议）](/docs/overview/transport/)
- [SSU2 Specification](/docs/specs/ssu2/) 和 [NTCP2 Specification](/docs/specs/ntcp2/)
