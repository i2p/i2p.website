---
title: "SSU2"
number: "159"
author: "eyedeekay, orignal, zlatinb, zzz"
created: "2021-09-12"
lastupdated: "2025-03-05"
status: "Closed"
thread: "http://zzz.i2p/topics/2612"
target: "0.9.56"
---

## Status

Plano de implantação:


| Recurso | Testando (não padrão) | Habilitado por padrão |
|---------|-----------------------|-----------------------|
| Código de teste local | 2022-02 |
| Código de teste conjunto | 2022-03 |
| Teste conjunto na rede | 0.9.54 | 2022-05 |
| Congelar protocolo básico | 0.9.54 | 2022-05 |
| Sessão Básica | 0.9.55 | 2022-08 | 0.9.56 | 2022-11 |
| Validação de Endereço (Retentar) 0.9.55 | 2022-08 | 0.9.56 | 2022-11 |
| RI Fragmentado no handshake | 0.9.55 | 2022-08 | 0.9.56 | 2022-11 |
| Novo Token | 0.9.55 | 2022-08 | 0.9.57 | 2022-11 |
| Congelar protocolo estendido | 0.9.55 | 2022-08 |
| Relay | 0.9.55 | 2022-08 | 0.9.56 | 2022-11 |
| Teste de Par | 0.9.55 | 2022-08 | 0.9.56 | 2022-11 |
| Habilitar para 2% aleatórios | 0.9.55 | 2022-08 |
| Validação de Caminho | 0.9.55+ dev | 0.9.56 | 2022-11 |
| Migração de Conexão | 0.9.55+ dev | 0.9.56 | 2022-11 |
| Flag de ACK Imediato | 0.9.55+ dev | 0.9.56 | 2022-11 |
| Rotação de Chaves | 0.9.57 | 2023-02 | 0.9.58 | 2023-05 |
| Desativar SSU 1 (i2pd) | 0.9.56 | 2022-11 |
| Desativar SSU 1 (Java I2P) | 0.9.58 | 2023-05 | 0.9.61 | 2023-12 |

Sessão Básica inclui o handshake e a fase de dados.
Protocolo estendido inclui relay e teste de par.



## Visão Geral

Esta proposta descreve um protocolo de acordo de chave autenticado para melhorar a
resistência do [SSU](/en/docs/transport/ssu/) a várias formas de identificação automatizada e ataques.

A proposta está organizada da seguinte forma: os objetivos de segurança são apresentados,
seguido por uma discussão do protocolo básico. Em seguida, uma especificação completa
de todas as mensagens do protocolo é fornecida. Finalmente, são discutidos os endereços dos roteadores e a identificação de versão.

Como outros transportes I2P, o SSU2 é definido
para transporte ponto-a-ponto (roteador-para-roteador) de mensagens I2NP.
Não é um canal de dados de propósito geral.
Assim como o [SSU](/en/docs/transport/ssu/), também fornece dois serviços adicionais:
Relay para travessia de NAT, e Teste de Par para determinação de alcançabilidade inbound.
Ele também fornece um terceiro serviço, não presente no SSU, para migração de conexão
quando um par muda de IP ou porta.


## Motivação

SSU é a única camada de protocolo restante que requer ElGamal, o que é muito lento.
O controle de fluxo para SSU é complexo e não funciona bem.
Porções do SSU são vulneráveis a ataques de spoofing de endereço.
O handshake não usa Noise.



## Objetivos de Projeto

- Reduzir o uso de CPU eliminando ElGamal. Usar X25519 para o DH.

- Manter as funções de Teste de Par e Relay, e aumentar a segurança para elas.

- Facilitar a implementação permitindo algoritmos padrão de controle de fluxo.

- Reduzir a latência de configuração.
  O tempo mediano de configuração atualmente é de cerca de 135 ms para NTCP2 e 187 ms para SSU,
  mesmo que o NTCP2 tenha uma viagem extra de ida e volta; substituir ElGamal no
  SSU2 deve reduzi-lo, mas outras mudanças também podem ajudar.

- Manter ou aumentar a taxa de transferência máxima comparado ao SSU 1,
  medido em uma faixa de latências simuladas e porcentagens de descarte de pacotes em uma rede de teste.

- Prevenir amplificação de tráfego e ataques de roteamento incorreto de endereços de origem falsificados
  via "validação de endereço".

- Facilitar a identificação de pacotes, para reduzir a dependência de fallbacks e
  heurísticas que tornam o código excessivamente complexo.

- Formalizar e melhorar a migração de conexão quando o IP ou a porta do par mudam.
  Não migrar conexões até a validação do endereço ser concluída, para prevenir ataques.
  Algumas implementações do SSU 1 usam heurísticas caras para lidar com mudanças de porta
  devido a rebinding de NAT. Nenhuma implementação do SSU 1 conhecida pode lidar com alterações de IP.

- Suportar SSU 1 e 2 em uma única porta, detecção automática, e publicado como um único
  "transporte" (ou seja, [RouterAddress](/en/docs/spec/common-structures/#routeraddress/)) no [NetDB](/en/docs/how/network-database/).

- Publicar suporte para a versão 1 apenas, 2 apenas, ou 1+2 no NetDB em um campo separado, e
  por padrão para a versão 1 apenas (não amarrar o suporte a versões a um
  versão específica do roteador)

- Assegurar que todas as implementações (Java/i2pd/Go) possam adicionar suporte à versão 2
  (ou não) em seus próprios cronogramas

- Adicionar preenchimento aleatório a todas as mensagens incluindo mensagens de handshake e dados.
  Todo preenchimento deve ser coberto pelo MAC, ao contrário do preenchimento no final do pacote no SSU 1.
  Fornecer mecanismo de opções para ambos os lados solicitarem preenchimento min e max
  e/ou distribuição de preenchimento. Específicos da distribuição de preenchimento são
  dependentes da implementação e podem ou não ser especificados no próprio protocolo.

- Obfuscar os cabeçalhos e conteúdos de mensagens que não estão totalmente criptografados
  suficientemente para que caixas de DPI e assinaturas AV não possam facilmente classificá-los.
  Além disso, assegurar que as mensagens enviadas a um único par ou conjunto de pares não
  tenham um padrão semelhante de bits.

- Corrigir perda de bits no DH devido ao formato Java [Ticket1112](http://{{ i2pconv('trac.i2p2.i2p') }}/ticket/1112), e acelerar o DH
  mudando para X25519.

- Mudar para uma função de derivação de chave real (KDF) em vez de usar o resultado do DH
  como está

- Adicionar "resistência a sondagens" (como o Tor chama); isso inclui resistência a replays.

- Manter troca de chave autenticada bidirecional (2W-AKE). 1W-AKE não é suficiente
  para nossa aplicação.

- Contar com a chave pública estática publicada no RouterInfo como outra parte da
  autenticação.

- Adicionar opções/versão no handshake para futura extensibilidade.

- Não adicionar significativamente ao CPU necessário para configuração de conexão; se possível,
  reduzi-lo significativamente.

- Remover requisito de preenchimento para múltiplos de 16 bytes
  imposto pela criptografia AES no SSU 1.

- Usar ChaCha/Poly1305 padrão para criptografia e MAC,
  substituindo a criptografia AES e o MAC não padrão HMAC-MD5-128 usado no SSU 1.

- Usar chaves de criptografia separadas para envio e recebimento, em vez
  das chaves comuns para ambas direções usadas no SSU 1.

- Usar um handshake de três mensagens, de uma rodada de ida e volta, como no [NTCP2](/en/proposals/111-ntcp-2/).
  Remover o atraso esperando por mensagens de dados que tornam [SSU](/en/docs/transport/ssu/)
  efetivamente um handshake de duas rodadas de ida e volta.

- Melhorar dramaticamente a eficiência de ACKs e NACKs,
  que é horrível no SSU 1. Reduzir a largura de banda requerida
  para ACKs e NACKs, e aumentar o tamanho do pacote disponível para dados.
  Codificar eficientemente NACKs para um estouro de mensagens faltantes,
  o que é comum em WiFi.

- Reduzir a complexidade necessária para implementar a fragmentação de mensagens I2NP.
  Ignorar mecanismos de fragmentação e codificação para mensagens I2NP completas.

- Minimizar a sobrecarga do protocolo antes do preenchimento, especialmente para ACKs.
  Embora o preenchimento será adicionado,
  a sobrecarga antes do preenchimento ainda é sobrecarga.
  Nós de baixa largura de banda devem ser capazes de usar SSU2.

- Manter timestamps para detecção de replay e diferenças.

- Evitar quaisquer problemas de ano 2038 em timestamps, deve funcionar até pelo menos 2106.

- Aumentar o MTU mínimo de 620 para 1280 pela eficiência, facilidade de implementação,
  e aumento do tamanho máximo da mensagem I2NP.
  Fragmentação e remontagem são bastante custosas.
  Ao fornecer espaço para mensagens de túnel de 1028 bytes, uma grande maioria das mensagens I2NP
  não precisará de fragmentação.

- Aumentar o MTU máximo de 1488 (1484 para IPv6) para 1500 pela eficiência.
  Remover o requisito de que o MTU seja um múltiplo de 16.

- Aumentar o tamanho máximo da mensagem I2NP de aproximadamente 32K no SSU 1
  para aproximadamente 64 KB como no NTCP2.

- Remover a assinatura dos campos IP e porta do handshake,
  para que roteadores que não sabem
  seu IP externo e porta possam conectar.

- Reter o mecanismo de descoberta de IP/porta do SSU 1 no handshake,
  para que roteadores possam aprender seu IP externo e porta.

- Incluir representantes dos desenvolvedores de roteadores Java, C++ e Go no projeto.



### Não-Objetivos

- Resistência bulletproof a DPI... que seriam transportes plugáveis,
  [Prop109](/en/proposals/109-hashcash/).

- Um transporte baseado em TLS (ou semelhante a HTTPS)... que seria [Prop104](/en/proposals/104-new-protocol/).

- Resistência a DPI baseado em temporização (temporização/delays inter-mensagem podem ser
  dependentes de implementação; delays intra-mensagem podem ser introduzidos em qualquer
  ponto, incluindo antes de enviar o preenchimento aleatório, por exemplo). Delays artificiais
  (o que obfs4 chama de IAT ou tempo de interchegada) são independentes do
  próprio protocolo.

- Negação de participação em uma sessão (há assinaturas ali).

Não-objetivos que podem ser parcialmente reconsiderados ou discutidos:

- O grau de proteção contra Inspeção Profunda de Pacotes (DPI)

- Segurança Pós-Quântica (PQ)

- Negação



## Objetivos de Segurança

Consideramos três partes:

- Alice, que deseja estabelecer uma nova sessão.
- Bob, com quem Alice deseja estabelecer uma sessão.
- Mallory, o "homem no meio" entre Alice e Bob.

No máximo dois participantes podem se envolver em ataques ativos.

Alice e Bob estão ambos em posse de um par de chaves estático, que está contido
em seus [RouterIdentity](/en/docs/spec/common-structures/#routeridentity/).

O protocolo proposto tenta permitir que Alice e Bob concordem com uma chave
secreta compartilhada (K) sob os seguintes requisitos:

1) Segurança da chave privada: nem Bob nem Mallory aprendem algo sobre a
   chave privada estática de Alice. Simetricamente, Alice não aprende nada sobre a
   chave privada estática de Bob.

2) A chave de sessão K é conhecida apenas por Alice e Bob.

3) Sigilo direto perfeito: a chave de sessão acordada permanece secreta no
   futuro, mesmo quando as chaves privadas estáticas de Alice e/ou Bob são reveladas
   após a chave ter sido acordada.

4) Autenticação bidirecional: Alice tem certeza de que estabeleceu uma sessão
   com Bob, e vice-versa.

5) Proteção contra DPI online: Assegurar que não é trivial detectar que
   Alice e Bob estão engajados no protocolo usando apenas técnicas simples de
   inspeção profunda de pacotes (DPI). Ver abaixo.

6) Negação limitada: nem Alice nem Bob podem negar participação no
   protocolo, mas se algum vazá a chave compartilhada a outra parte pode negar a
   autenticidade do conteúdo dos dados transmitidos.

A proposta atual tenta fornecer todos os cinco requisitos baseados no
protocolo Station-To-Station (STS) [STS](https://en.wikipedia.org/wiki/Station-to-Station_protocol). Note que este protocolo é também a
base para o protocolo [SSU](/en/docs/transport/ssu/).


### Discussão Adicional sobre DPI

Assumimos dois componentes de DPI:

DPI online
`````````````

DPI online inspecionando todos os fluxos em tempo real. Conexões podem ser bloqueadas ou
alteradas de outras formas. Dados de conexão ou metadados podem ser identificados e
armazenados para análise offline. O DPI online não tem acesso ao
banco de dados da rede I2P. O DPI online tem apenas capacidade computacional
limitada em tempo real, incluindo cálculo de comprimento, inspeção de campo, e
cálculos simples como XOR. O DPI online tem a capacidade de realizar
funções criptográficas rápidas em tempo real como ChaCha20, AEAD, e hashing, mas
seria muito caro aplicá-las à maioria ou a todos os fluxos. Qualquer aplicação
destas operações criptográficas aplicaria apenas a fluxos em combinações
IP/Port previamente identificadas por análise offline. O DPI online não tem a
capacidade de realizar funções criptográficas de custo elevado como DH ou elligator2.
O DPI online não é projetado especificamente para detectar I2P, embora possa ter
regras de classificação limitadas para esse propósito.

É um objetivo impedir a identificação de protocolos por um DPI online.

A noção de DPI online ou "simples" aqui é considerada para incluir as
capacidades do adversário:

1) A capacidade de inspecionar todos os dados enviados ou recebidos pelo alvo.

2) A capacidade de realizar operações nos dados observados, como
   aplicar cifradores de bloco ou funções hash.

3) A capacidade de armazenar e comparar com mensagens enviadas anteriormente.

4) A capacidade de modificar, atrasar ou fragmentar pacotes.

No entanto, assume-se que o DPI online possui as seguintes restrições:

5) A incapacidade de mapear endereços IP para hashes de roteadores. Embora seja trivial
   com acesso em tempo real ao banco de dados da rede,
   exigiria um sistema de DPI projetado especificamente para direcionar I2P.

6) A incapacidade de usar informações de temporização para detectar o protocolo.

7) De modo geral, a caixa de ferramentas do DPI online não contém nenhuma ferramenta
   integrada criada especificamente para detecção de I2P. Isso inclui
   criar "armadilhas", que por exemplo, incluiriam preenchimento não aleatório em
   suas mensagens. Note-se que isso não exclui sistemas de aprendizado de máquina ou
   ferramentas de DPI altamente configuráveis, desde que atendam aos
   outros requisitos.

Para combater a análise do payload, é garantido que todas as mensagens sejam
indistinguíveis do aleatório. Isso também exige que seus comprimentos sejam aleatórios,
o que é mais complicado do que apenas adicionar preenchimento aleatório. De fato, no Apêndice
A, os autores argumentam que um esquema de preenchimento ingênuo (ou seja, uniforme) não
resolve o problema. O Apêndice A, portanto, propõe incluir atrasos aleatórios ou desenvolver
um esquema alternativo de preenchimento que possa prover uma proteção razoável para o
ataque proposto.

Para proteger contra a sexta entrada acima, as implementações devem incluir atrasos
aleatórios no protocolo. Tais técnicas não estão cobertas por esta proposta; no entanto,
poderiam também resolver os problemas com o comprimento do preenchimento. Em conclusão, a
proposta oferece proteção robusta contra análise do payload (levando em conta as
considerações no Apêndice A), mas apenas proteção limitada contra análise de fluxo.


DPI offline
``````````````

DPI offline inspecionando dados armazenados pelo DPI online para análise posterior.
O DPI offline pode ser projetado especificamente para detectar I2P.
O DPI offline tem acesso em tempo real ao banco de dados da rede I2P.
O DPI offline tem acesso a esta e outras especificações do I2P.
O DPI offline possui capacidade computacional ilimitada, incluindo
todas as funções criptográficas definidas nesta especificação.

O DPI offline não tem a habilidade de bloquear conexões existentes.
O DPI offline tem a capacidade de enviar para o host/porta das partes por meio de
injeção de pacotes em quase tempo real (dentro de minutos da configuração).
O DPI offline tem a capacidade de realizar replay
de mensagens anteriores (modificadas ou não) para "sondar" ou outras razões quase
em tempo real (dentro de minutos da configuração).

Não é um objetivo evitar a identificação de protocolos por um DPI offline.
Toda a decodificação de dados ofuscados nas duas primeiras mensagens, que
é implementada por roteadores I2P, também pode ser implementada pelo DPI offline.

É um objetivo rejeitar conexões tentativas usando replay de mensagens anteriores.



### Validação de Endereços

O seguinte é copiado do QUIC [RFC-9000](https://www.rfc-editor.org/rfc/rfc9000.html).
Para cada seção, revisa e edita.

A validação de endereço assegura que um endpoint não pode ser usado para um
ataque de amplificação de tráfego. Nesse tipo de ataque, um pacote é enviado
para um servidor com informações de endereço de origem falsificadas que identificam uma
vítima. Se o servidor gerar mais ou maiores pacotes em resposta a
aquele pacote, o atacante pode usar o servidor para enviar mais dados
na direção da vítima do que conseguiria enviar por conta própria.

A defesa primária contra ataques de amplificação é verificar se um
par é capaz de receber pacotes no endereço de transporte que
declara. Portanto, após receber pacotes de um endereço que não é
ainda validado, um endpoint DEVE limitar a quantidade de dados que envia
para o endereço não validado para três vezes a quantidade de dados recebidos
daquele endereço. Esse limite no tamanho das respostas é
conhecido como o limite de anti-amplificação.

A validação de endereço é realizada tanto durante o estabelecimento da conexão
(ver Seção 8.1) quanto durante a migração da conexão (ver Seção 8.2).

Validação de Endereço durante Estabelecimento de Conexão
```````````````````````````````````````````````````````

O estabelecimento da conexão implicitamente fornece validação de endereço para
ambos os endpoints. Em particular, o recebimento de um pacote protegido com
chaves de handshake confirma que o peer processou com sucesso um
pacote Inicial. Uma vez que um endpoint tenha processado com sucesso um
pacote Handshake do peer, ele pode considerar que o endereço do peer foi
validado.

Além disso, um endpoint PODE considerar o endereço do peer validado se
o peer usar um ID de conexão escolhido pelo endpoint e o
ID de conexão contiver pelo menos 64 bits de entropia.

Para o cliente, o valor do campo Destination Connection ID em
seu primeiro pacote Inicial permite que ele valide o endereço do servidor como
parte do processamento bem-sucedido de qualquer pacote. Pacotes Iniciais
do servidor são protegidos com chaves que são derivadas desse valor
(ver Seção 5.2 de [QUIC-TLS]). Alternativamente, o valor é repetido
pelo servidor em pacotes de Negociação de Versão (Seção 6) ou incluído
no Tag de Integridade em pacotes de Retry (Seção 5.8 de [QUIC-TLS]).

Antes de validar o endereço do cliente, servidores NÃO DEVEM enviar mais
do que três vezes a quantidade de bytes que receberam. Isso limita a
magnitude de qualquer ataque de amplificação que pode ser montado usando
endereços falsificados. Para os propósitos de evitar amplificação antes da
validação de endereço, servidores DEVEM contar todos os bytes de payload recebidos em datagramas que
são atribuídos unicamente a uma única conexão. Isso inclui datagramas
que contêm pacotes que são processados com sucesso e datagramas
que contêm pacotes que são todos descartados.

Clientes DEVEM assegurar que datagramas UDP contendo pacotes Iniciais
tenham payloads UDP de pelo menos 1200 bytes, adicionando frames PADDING conforme
necessário. Um cliente que envia datagramas preenchidos permite que o servidor
envie mais dados antes de completar a validação de endereço.

A perda de um pacote Inicial ou Handshake no servidor pode causar um
deadlock se o cliente não enviar pacotes Iniciais ou Handshake adicionais.
Um deadlock poderia ocorrer quando o servidor atinge seu limite de anti-
amplificação e o cliente recebeu acknowledges por
todos os dados que enviou. Nesse caso, quando o cliente não tem
razão para enviar pacotes adicionais, o servidor não poderá enviar
mais dados porque não validou o endereço do cliente. Para
prevenir este deadlock, clientes DEVEM enviar um pacote em um Timeout de Sonda
(PTO); ver Seção 6.2 de [QUIC-RECOVERY]. Especificamente, o cliente
DEVE enviar um pacote Inicial em um datagrama UDP que tenha pelo menos
1200 bytes se não tiver chaves de Handshake, e caso contrário, enviar um
pacote Handshake.

Um servidor pode desejar validar o endereço do cliente antes de começar
o handshake criptográfico. O QUIC usa um token no pacote Inicial
para fornecer validação de endereço antes de completar o handshake.
Este token é entregue ao cliente durante o estabelecimento da conexão
com um pacote Retry (ver Seção 8.1.2) ou em uma conexão anterior
usando o frame NEW_TOKEN (ver Seção 8.1.3).

Além dos limites de envio impostos antes da validação do endereço,
os servidores também são limitados no que podem enviar pelos limites definidos
pelo controlador de congestionamento. Clientes são limitados apenas pelo
controlador de congestionamento.

Construção de Token
```````````````````````````````````````````````````````

Um token enviado em um frame NEW_TOKEN ou um pacote Retry DEVE ser
construído de maneira que permita ao servidor identificar como ele foi
fornecido a um cliente. Esses tokens são transportados no mesmo campo, mas
requerem tratamento diferente dos servidores.

Validação de Endereço Usando Pacotes Retry
```````````````````````````````````````````````````````

Após receber o pacote Inicial do cliente, o servidor pode solicitar
validação de endereço enviando um pacote Retry (Seção 17.2.5)
contendo um token. Este token DEVE ser repetido pelo cliente em todos
os pacotes Iniciais que enviar para aquela conexão após receber o
pacote Retry.

Em resposta ao processamento de um pacote Inicial contendo um token que
foi fornecido em um pacote Retry, um servidor não pode enviar outro
pacote Retry; ele só pode recusar a conexão ou permitir que ela continue.

Contanto que não seja possível para um atacante gerar um token válido
para seu próprio endereço (ver Seção 8.1.4) e o cliente seja capaz
de retornar aquele token, ele prova ao servidor que recebeu o
token.

Um servidor também pode usar um pacote Retry para adiar o estado e
custos de processamento do estabelecimento da conexão. Requerer que o
servidor forneça um ID de conexão diferente, junto com o
parâmetro de transporte original_destination_connection_id definido na
Seção 18.2, força o servidor a demonstrar que ele, ou uma entidade
com a qual coopera, recebeu o pacote Inicial original do
cliente. Fornecer um ID de conexão diferente também concede ao servidor
algum controle sobre como os pacotes subsequentes são roteados. Isso pode ser
usado para direcionar conexões para uma instância de servidor diferente.

Se um servidor receber um Inicial de cliente que contém um token Retry
inválido, mas é de outra forma válido, ele sabe que o cliente não
aceitará outro token Retry. O servidor pode descartar tal pacote e permitir
que o cliente perca tempo para detectar falha de handshake, mas isso poderia
impor uma penalidade significativa de latência para o cliente. Em vez disso, o
servidor DEVE fechar imediatamente (Seção 10.2) a conexão com um
erro INVALID_TOKEN. Note que um servidor ainda não estabeleceu qualquer
estado para a conexão neste ponto e, portanto, não entra no
período de encerramento.

Um fluxo mostrando o uso de um pacote Retry é mostrado na Figura 9.

```
Client                                                  Server

  Initial[0]: CRYPTO[CH] ->

                                                <- Retry+Token

  Initial+Token[1]: CRYPTO[CH] ->

                                 Initial[0]: CRYPTO[SH] ACK[1]
                       Handshake[0]: CRYPTO[EE, CERT, CV, FIN]
                                 <- 1-RTT[0]: STREAM[1, "..."]

                Figure 9: Handshake com Retry
```



Validação de Endereço para Conexões Futuras
```````````````````````````````````````````````````````

Um servidor PODE fornecer aos clientes um token de validação de endereço durante
uma conexão que pode ser usado em uma conexão subsequente. A validação
de endereço é especialmente importante com 0-RTT porque um servidor
potencialmente envia uma quantidade significativa de dados para um cliente em
resposta a dados 0-RTT.

O servidor usa o frame NEW_TOKEN (Seção 19.7) para fornecer ao
cliente um token de validação de endereço que pode ser usado para validar
futuras conexões. Em uma conexão futura, o cliente inclui este
token nos pacotes Iniciais para fornecer validação de endereço. O cliente
DEVE incluir o token em todos os pacotes Iniciais que enviar, a menos que
um Retry substitua o token por um mais recente. O cliente NÃO DEVE usar
o token fornecido em um Retry para futuras conexões. Servidores PODEM
descartar qualquer pacote Inicial que não transporte o token esperado.

Ao contrário do token que é criado para um pacote Retry, que é usado
imediatamente, o token enviado no frame NEW_TOKEN pode ser usado após
algum tempo ter passado. Assim, um token DEVE ter um
tempo de expiração, que pode ser um tempo de expiração explícito ou
um carimbo de data e hora emitido que pode ser usado para calcular dinamicamente o
tempo de expiração. Um servidor pode armazenar o tempo de expiração ou incluí-lo
em uma forma criptografada no token.

Um token emitido com NEW_TOKEN NÃO DEVE incluir informações que
permitam valores a serem vinculados por um observador à conexão em que
foi emitido. Por exemplo, ele não pode incluir o ID de conexão anterior ou
informações de endereçamento, a menos que os valores sejam
criptografados. Um servidor DEVE assegurar que cada frame NEW_TOKEN que
enviar seja único para todos os clientes, com exceção daqueles enviados para
reparar perdas de frames NEW_TOKEN enviados anteriormente. Informação que
permite ao servidor distinguir entre tokens de Retry e
NEW_TOKEN PODE estar acessível a entidades além do servidor.

É improvável que o número da porta do cliente seja o mesmo em duas
diferentes conexões; validar a porta é, portanto, improvável que
seja bem-sucedido.

Um token recebido em um frame NEW_TOKEN é aplicável a qualquer servidor
para o qual a conexão é considerada autorizativa (por exemplo, nomes de servidor
incluídos no certificado). Ao conectar-se a um servidor para
o qual o cliente mantém um token aplicável e não usado, ele DEVE
incluir esse token no campo Token do seu pacote Inicial.
Incluir um token pode permitir que o servidor valide o endereço do cliente
sem uma viagem de ida e volta adicional. Um cliente NÃO DEVE incluir
um token que não seja aplicável ao servidor com o qual está se conectando,
a menos que o cliente tenha conhecimento de que o servidor que emitiu
o token e o servidor ao qual o cliente está se conectando estão gerenciando
juntamente os tokens. Um cliente PODE usar um token de qualquer conexão
anterior com esse servidor.

Um token permite que um servidor correlacione atividades entre a conexão em
que o token foi emitido e qualquer conexão em que
ele é usado. Clientes que desejam quebrar a continuidade de identidade
com um servidor podem descartar tokens fornecidos usando o frame NEW_TOKEN.
Em comparação, um token obtido em um pacote Retry DEVE ser usado
imediatamente durante a tentativa de conexão e não pode ser usado em
tentativas de conexão subsequentes.

Um cliente NÃO DEVE reutilizar um token de um frame NEW_TOKEN para
diferentes tentativas de conexão. Reutilizar um token permite que conexões
sejam vinculadas por entidades no caminho da rede; ver Seção 9.5.

Clientes podem receber múltiplos tokens em uma única conexão. Além
de prevenir a vinculabilidade, qualquer token pode ser usado em qualquer tentativa
de conexão. Servidores podem enviar tokens adicionais para habilitar a
validação de endereço para múltiplas tentativas de conexão ou substituir
tokens mais antigos que podem se tornar inválidos. Para um cliente, esta
ambiguidade significa que enviar o token novo não usado recentemente é o mais provável
de ser eficaz. Embora salvar e usar tokens antigos não tenha consequências negativas,
clientes podem considerar tokens mais antigos como sendo menos prováveis
de serem úteis para o servidor para validação de endereço.

Quando um servidor recebe um pacote Inicial com um token de validação de
endereço, ele DEVE tentar validar o token, a menos que já tenha
concluído a validação do endereço. Se o token for inválido, então o
servidor DEVE prosseguir como se o cliente não tivesse um
endereço validado, incluindo potencialmente enviar um pacote Retry.
Tokens fornecidos com frames NEW_TOKEN e pacotes Retry podem ser
distintos por servidores (ver Seção 8.1.1), e os últimos podem ser
validados mais estritamente. Se a validação for bem-sucedida, o servidor DEVE
então permitir que o handshake prossiga.

Nota: A justificativa para tratar o cliente como não validado
em vez de descartar o pacote é que o cliente pode ter
recebido o token em uma conexão anterior usando o frame NEW_TOKEN,
e se o servidor perdeu o estado, ele pode ser incapaz de
validar o token completamente, levando a falha na conexão se o
pacote for descartado.

Em um design sem estado, um servidor pode usar tokens criptografados e autenticados
para passar informações para clientes que o servidor pode depois
recuperar e usar para validar um endereço do cliente. Tokens não são
integrados ao handshake criptográfico e, portanto, não são
autenticados. Por exemplo, um cliente pode ser capaz de reutilizar um
token. Para evitar ataques que exploram esta propriedade, um servidor pode
limitar o uso de tokens apenas à informação necessária para validar
endereços de clientes.

Clientes PODEM usar tokens obtidos em uma conexão para qualquer tentativa de
conexão usando a mesma versão. Ao selecionar um token a ser usado,
clientes não precisam considerar outras propriedades da conexão
que está sendo tentada, incluindo a escolha de possíveis protocolos
de aplicação, tickets de sessão, ou outras propriedades da
conexão.

Integridade de Token de Validação de Endereço
```````````````````````````````````````````````````````

Um token de validação de endereço DEVE ser difícil de adivinhar.  Incluir um
valor aleatório com pelo menos 128 bits de entropia no token seria
suficiente, mas isto depende do servidor lembrar o valor que
envia aos clientes.

Um esquema baseado em token permite ao servidor transferir qualquer
estado associado à validação para o cliente.  Para este design funcionar,
o token DEVE ser coberto por proteção de integridade contra
modificação ou falsificação por clientes.  Sem proteção de
integridade, clientes maliciosos poderiam gerar ou adivinhar valores para
tokens que seriam aceitos pelo servidor.  Somente o servidor
requere acesso à chave de proteção de integridade para tokens.

Não há necessidade de um formato bem definido único para o token
porque o servidor que gera o token também o consome.  Tokens
enviados em pacotes Retry DEVE incluir informações que permitam o
servidor verificar se o endereço IP e porto de origem nos pacotes do
cliente permanecem constantes.

Tokens enviados em frames NEW_TOKEN DEVE incluir informações que permitem
o servidor verificar que o endereço IP do cliente não mudou desde
quando o token foi emitido.  Servidores podem usar tokens de frames NEW_TOKEN
para decidir não enviar um pacote Retry, mesmo que o endereço do
cliente tenha mudado.  Se o endereço IP do cliente mudou, o
servidor DEVE aderir ao limite de anti-amplificação; ver Seção 8.
Note que na presença de NAT, este requisito pode ser
insuficiente para proteger outros hosts que compartilham o NAT de
ataques de amplificação.

Atacantes podem reproduzir tokens para usar servidores como amplificadores em ataques DDoS.
Para se proteger contra tais ataques, os servidores DEVEM assegurar que
a repetição de tokens seja prevenida ou limitada.  Os servidores DEVEM assegurar que
os tokens enviados em pacotes Retry sejam aceitos apenas por um curto período de tempo, já que
são imediatamente retornados pelos clientes.  Tokens que são fornecidos
em frames NEW_TOKEN (Seção 19.7) precisam ser válidos por mais tempo, mas NÃO
DEVEM ser aceitos múltiplas vezes.  Os servidores são incentivados a
permitir que tokens sejam usados apenas uma vez, se possível; tokens PODEM incluir
informações adicionais sobre clientes para reduzir ainda mais a aplicabilidade ou
reuso.

Validação de Caminho
`````````````````````````````````````````````````````````;

A validação de caminho é usada por ambos os pares durante a migração de conexão
(veja a Seção 9) para verificar a alcançabilidade após uma mudança de endereço. Em
a validação de caminho, os endpoints testam a alcançabilidade entre um endereço local
específico e um endereço do par específico, onde um endereço é o 2-tuplo
de endereço IP e porta.

A validação de caminho testa se os pacotes enviados em um caminho para um par são
recebidos por esse par. A validação de caminho é usada para garantir que
pacotes recebidos de um par migrante não carreguem um endereço de origem falsificado.

A validação de caminho não valida que um par possa enviar na direção de retorno. Os reconhecimentos não podem ser usados para validação de caminho de retorno porque eles contêm entropia insuficiente e podem ser falsificados. Os endpoints determinam independentemente a alcançabilidade em cada direção de um caminho, e, portanto, a alcançabilidade de retorno só pode ser estabelecida pelo par.

A validação de caminho pode ser usada a qualquer momento por qualquer um dos endpoints. Por exemplo, um endpoint pode verificar se um par ainda está na posse de seu endereço após um período de inatividade.

A validação de caminho não é projetada como um mecanismo de travessia de NAT. Embora o mecanismo aqui descrito possa ser eficaz para a criação de vínculos NAT que suportam a travessia NAT, a expectativa é que um endpoint seja capaz de receber pacotes sem primeiro ter enviado um pacote nesse caminho. Uma travessia NAT efetiva precisa de mecanismos adicionais de sincronização que não são fornecidos aqui.

Um endpoint PODE incluir outros frames com os frames PATH_CHALLENGE e PATH_RESPONSE utilizados para validação de caminho. Em particular, um endpoint pode incluir frames PADDING com um frame PATH_CHALLENGE para descoberta de MTU máximo de caminho (PMTUD); ver Seção 14.2.1. Um endpoint pode também incluir seu próprio frame PATH_CHALLENGE ao enviar um frame PATH_RESPONSE.

Um endpoint usa um novo ID de conexão para sondas enviadas de um novo endereço local; ver Seção 9.5. Ao sondar um novo caminho, um endpoint pode assegurar que seu par tenha um ID de conexão não utilizado disponível para respostas. Enviar frames NEW_CONNECTION_ID e PATH_CHALLENGE no mesmo pacote, se o limite active_connection_id_limit do par permitir, assegura que um ID de conexão não utilizado estará disponível para o par ao enviar uma resposta.

Um endpoint pode optar por sondar simultaneamente múltiplos caminhos. O número de caminhos simultâneos usados para sondas é limitado pelo número de IDs de conexão extras que seu par forneceu anteriormente, uma vez que cada novo endereço local usado para uma sonda requer um ID de conexão previamente não utilizado.

Iniciar Validação de Caminho
```````````````````````````````````````````````````````

Para iniciar a validação de caminho, um endpoint envia um frame PATH_CHALLENGE contendo uma payload imprevisível no caminho a ser validado.

Um endpoint PODE enviar múltiplos frames PATH_CHALLENGE para se proteger contra a perda de pacotes. No entanto, um endpoint NÃO DEVE enviar múltiplos frames PATH_CHALLENGE em um único pacote.

Um endpoint NÃO DEVE sondar um novo caminho com pacotes contendo um frame PATH_CHALLENGE mais frequentemente do que enviaria um pacote Inicial. Isso garante que a migração de conexão não seja mais carga em um novo caminho do que o estabelecimento de uma nova conexão.

O endpoint DEVE usar dados imprevisíveis em cada frame PATH_CHALLENGE para que ele possa associar a resposta do peer com o respectivo PATH_CHALLENGE.

Um endpoint DEVE expandir datagramas que contenham um frame PATH_CHALLENGE para pelo menos o menor tamanho máximo permitido de datagrama de 1200 bytes, a menos que o limite de anti-amplificação para o caminho não permita enviar um datagrama desse tamanho. Enviar datagramas UDP desse tamanho garante que o caminho de rede do endpoint para o peer possa ser usado para QUIC; ver Seção 14.

Quando um endpoint é incapaz de expandir o tamanho do datagrama para 1200 bytes devido ao limite de anti-amplificação, o MTU do caminho não será validado. Para garantir que o MTU do caminho seja grande o suficiente, o endpoint DEVE realizar uma segunda validação de caminho enviando um frame PATH_CHALLENGE em um datagrama de pelo menos 1200 bytes. Essa validação adicional pode ser realizada após um FRAME RESPONSE ser recebido com sucesso ou quando bytes suficientes tenham sido recebidos no caminho para que o envio de um datagrama maior não resulte em exceder o limite de anti-amplificação.

Ao contrário de outros casos em que os datagramas são expandidos, endpoints NÃO DEVEM descartar datagramas que parecem muito pequenos quando contêm PATH_CHALLENGE ou PATH_RESPONSE.

Respostas de Validação de Caminho
```````````````````````````````````````````````````````

Ao receber um frame PATH_CHALLENGE, um endpoint DEVE responder ecoando os dados contidos no frame PATH_CHALLENGE em um frame PATH_RESPONSE. Um endpoint NÃO DEVE atrasar a transmissão de um pacote contendo um frame PATH_RESPONSE, a menos que seja limitado pelo controle de congestionamento.

Um frame PATH_RESPONSE DEVE ser enviado no caminho de rede onde o frame PATH_CHALLENGE foi recebido. Isso garante que a validação de caminho por um peer só seja bem-sucedida se o caminho for funcional em ambas direções. Esse requisito NÃO DEVE ser imposto pelo endpoint que inicia a validação de caminho, pois isso habilitaria um ataque à migração; ver Seção 9.3.3.

Um endpoint DEVE expandir datagramas que contenham um frame PATH_RESPONSE para pelo menos o menor tamanho máximo permitido de datagrama de 1200 bytes. Isso verifica que o caminho é capaz de transportar datagramas desse tamanho em ambas direções. No entanto, um endpoint NÃO DEVE expandir o datagrama contendo o PATH_RESPONSE se os dados resultantes excederem o limite de anti-amplificação. Espera-se que isso ocorra apenas se o PATH_CHALLENGE recebido não foi enviado em um datagrama expandido.

Um endpoint NÃO DEVE enviar mais de um frame PATH_RESPONSE em resposta a um frame PATH_CHALLENGE; ver Seção 13.3. O peer é esperado para enviar mais frames PATH_CHALLENGE conforme necessário para evocar frames PATH_RESPONSE adicionais.

Validação de Caminho Bem-Sucedida
```````````````````````````````````````````````````````

A validação de caminho é bem-sucedida quando um frame PATH_RESPONSE é recebido que contém os dados que foram enviados em um frame PATH_CHALLENGE anterior. Um frame PATH_RESPONSE recebido em qualquer caminho de rede valida o caminho no qual o PATH_CHALLENGE foi enviado.

Se um endpoint envia um frame PATH_CHALLENGE em um datagrama que não é expandido para pelo menos 1200 bytes e se a resposta a ele valida o endereço do peer, o caminho é validado, mas não o MTU do caminho. Como resultado, o endpoint pode agora enviar mais de três vezes a quantidade de dados que foi recebida. No entanto, o endpoint DEVE iniciar outra validação de caminho com um datagrama expandido para verificar que o caminho suporta o MTU requerido.

O recebimento de um reconhecimento para um pacote contendo um frame PATH_CHALLENGE não é uma validação adequada, uma vez que o reconhecimento pode ser falsificado por um peer malicioso.

Validação de Caminho Falida
```````````````````````````````````````````````````````

A validação de caminho só falha quando o endpoint que tenta validar o caminho abandona sua tentativa de validação do caminho.

Endpoints DEVEM abandonar a validação de caminho com base em um temporizador. Ao definir este temporizador, implementações são advertidas de que o novo caminho pode ter um tempo de ida e volta maior do que o original. Um valor de três vezes o maior dos atuais PTO ou o PTO para o novo caminho (usando kInitialRtt, conforme definido em [QUIC-RECOVERY]) é RECOMENDADO.

Este tempo limite permite que múltiplos PTOs expirem antes que a validação do caminho falhe, para que a perda de um único frame PATH_CHALLENGE ou PATH_RESPONSE não cause a falha da validação do caminho.

Note que o endpoint pode receber pacotes contendo outros frames no novo caminho, mas um frame PATH_RESPONSE com dados apropriados é requerido para que a validação do caminho seja bem-sucedida.

Quando um endpoint abandona a validação de caminho, determina que o caminho é inutilizável. Isso não implica necessariamente uma falha da conexão -- endpoints podem continuar enviando pacotes por outros caminhos conforme apropriado. Se nenhum caminho estiver disponível, um endpoint pode aguardar que um novo caminho se torne disponível ou fechar a conexão. Um endpoint que não possui um caminho de rede válido para seu peer PODE sinalizar isso usando o erro de conexão NO_VIABLE_PATH, observando que isso só é possível se o caminho de rede existir, mas não suporta o MTU requerido (Seção 14).

Uma validação de caminho pode ser abandonada por outras razões além da falha. Principalmente, isso acontece se uma migração de conexão para um novo caminho for iniciada enquanto uma validação de caminho no caminho antigo estiver em andamento.


### Migração de Conexão

O seguinte é copiado do QUIC [RFC-9000](https://www.rfc-editor.org/rfc/rfc9000.html).
Para cada seção, revise e edite.


O uso de um ID de conexão permite que conexões sobrevivam a alterações de
endereços de endpoint (endereço IP e porta), como as causadas por uma
migração do endpoint para uma nova rede. Esta seção descreve o
processo pelo qual um endpoint migra para um novo endereço.

O design do QUIC depende de endpoints retendo um endereço estável para
a duração do handshake. Um endpoint NÃO DEVE iniciar
migração de conexão antes que o handshake seja confirmado, conforme definido na
Seção 4.1.2 de [QUIC-TLS].

Se o peer enviou o parâmetro de transporte disable_active_migration, um
endpoint também NÃO DEVE enviar pacotes (incluindo pacotes de sondagem; ver
Seção 9.1) a partir de um endereço local diferente ao endereço o peer
utilizou durante o handshake, a menos que o endpoint tenha agido em um
parâmetro de transporte preferred_address do peer. Se o peer
violar este requisito, o endpoint DEVE descartar os pacotes
recebidos nesse caminho sem gerar um Reset Stateless ou
prosseguir com a validação do caminho e permitir que o peer migre. Gerar um
Reset Stateless ou fechar a conexão permitiria que terceiros
na rede fechassem conexões ao falsificar ou manipular o tráfego
observado.

Nem todas as alterações de endereço do peer são intencionais, ou migrações
ativas. O peer pode experimentar um reencaminhamento NAT: uma alteração de
endereço devido a um middlebox, geralmente um NAT, alocando uma nova
porta de saída ou até mesmo um novo endereço IP de saída para um fluxo.
Um endpoint DEVE realizar validação de caminho (Seção 8.2) se detectar
qualquer alteração no endereço de um peer, a menos que já tenha
validado esse endereço.

Quando um endpoint não possui um caminho validado no qual enviar pacotes, ele
PODE descartar o estado da conexão. Um endpoint capaz de
migração de conexão PODE esperar que um novo caminho se torne disponível antes
de descartar o estado da conexão.

Este documento limita a migração de conexões para novos
endereços de cliente, exceto conforme descrito na Seção 9.6. Clientes são
responsáveis por iniciar todas as migrações. Servidores não enviam pacotes não-
de sondagem (ver Seção 9.1) em direção a um endereço de cliente até que vejam um
pacote de sondagem do cliente a partir desse endereço. Se um cliente receber
pacotes de um endereço de servidor desconhecido, o cliente DEVE descartar esses
pacotes.

Sondando um Novo Caminho
```````````````````````````````

Um endpoint PODE sondar a alcançabilidade do peer a partir de um novo endereço local
usando validação de caminho (Seção 8.2) antes de migrar a conexão
para o novo endereço local. O fracasso da validação de caminho significa
simplesmente que o novo caminho não é utilizável para essa conexão. O fracasso
para validar um caminho não resulta no encerramento da conexão
a menos que não haja caminhos alternativos válidos disponíveis.

FRAME_CHALLENGE, PATH_RESPONSE, NEW_CONNECTION_ID e PADDING frames
são "frames de sondagem", e todos os outros frames são "frames de não-sondagem".
Um pacote contendo apenas frames de sondagem é um "pacote de sondagem", e um
pacote contendo qualquer outro frame é um "pacote de não-sondagem".

Iniciando Migração de Conexão
`````````````````````````````````````

Um endpoint pode migrar uma conexão para um novo endereço local
enviando pacotes contendo frames de não-sondagem a partir desse endereço.

Cada endpoint valida o endereço do peer durante o
estabelecimento da conexão. Portanto, um endpoint migrante pode enviar para seu peer
sabendo que o peer está disposto a receber no endereço atual do peer.
Assim, um endpoint pode migrar para um novo endereço local
sem primeiro validar o endereço do peer.

Para estabelecer a alcançabilidade no novo caminho, um endpoint inicia a
validação do caminho (Seção 8.2) no novo caminho. Um endpoint PODE adiar a
validação do caminho até que um peer envie o próximo frame de não-sondagem para seu
novo endereço.

Ao migrar, o novo caminho pode não suportar a taxa de
envio atual do endpoint. Portanto, o endpoint redefine o congestionamento
controlador e estimador de RTT, conforme descrito na Seção 9.4.

O novo caminho pode não ter a mesma capacidade de ECN.  Portanto, o
endpoint valida a capacidade de ECN conforme descrito na Seção 13.4.

Respondendo a Migração de Conexão
```````````````````````````````````````````

O recebimento de um pacote de um novo endereço de peer contendo um frame de
não-sondagem indica que o peer migrou para esse endereço.

Se o destinatário permitir a migração, ele DEVE enviar pacotes subsequentes
para o novo endereço de peer e DEVE iniciar validação do caminho
(Seção 8.2) para verificar a posse do endereço pelo peer se
a validação ainda não estiver em andamento. Se o destinatário não tiver IDs de
conexão não usadas do peer, ele não será capaz de enviar nada no
novo caminho até que o peer forneça um; ver Seção 9.5.

Um endpoint só altera o endereço para o qual envia pacotes em
resposta ao pacote de referência mais alto não-sondado. Isso assegura
que um endpoint não envie pacotes para um endereço antigo do peer no caso de
receber pacotes reordenados.

Um endpoint PODE enviar dados para um endereço de peer não validado, mas ele DEVE
se proteger contra possíveis ataques conforme descrito nas Seções 9.3.1 e
9.3.2. Um endpoint PODE pular a validação de um endereço de peer se esse
endereço tiver sido visto recentemente. Em particular, se um endpoint
retorna a um caminho previamente validado após detectar algum tipo de
migração espúria, pular a validação de endereço e restaurar o estado de perda
e congestionamento pode reduzir o impacto de desempenho do
ataque.

Após alterar o endereço para o qual envia pacotes de não-sondagem, um
endpoint pode abandonar qualquer validação de caminho para outros endereços.

Receber um pacote de um novo endereço de peer pode ser o resultado de um
reencaminhamento NAT no peer.

Após verificar um novo endereço de cliente, o servidor DEVE enviar novos
tokens de validação de endereço (Seção 8) para o cliente.

Falsificação de Endereço Peering
`````````````````````````````````

É possível que um peer esteja falsificando seu endereço de origem para causar um
endpoint enviar quantidades excessivas de dados para um host não desejoso. Se
o endpoint enviar significativamente mais dados do que o peer de falsificação,
a migração da conexão pode ser usada para amplificar o volume de dados que
um atacante pode gerar em direção a uma vítima.

Conforme descrito na Seção 9.3, um endpoint é exigido para validar um
novo endereço de peer para confirmar a posse do peer no novo
endereço. Até o endereço do peer ser considerado válido, um endpoint limita
a quantidade de dados que ele envia para esse endereço; ver Seção 8. Na
ausência desse limite, um endpoint corre o risco de ser usado para um ataque de
negação de serviço contra uma vítima desavisada.

Se um endpoint pular a validação de um endereço de peer conforme descrito acima,
ele não precisa limitar sua taxa de envio.

Falsificação de Endereço Fora da Linha
```````````````````````````````````

Um atacante fora da linha que pode observar pacotes pode encaminhar cópias de
pacotes genuínos para endpoints. Se o pacote copiado chegar antes
do pacote genuíno, isso aparecerá como um reencaminhamento NAT. Qualquer
pacote genuíno será descartado como um duplicado. Se o atacante
for capaz de continuar a encaminhar pacotes, ele pode ser capaz de
causar a migração para um caminho através do atacante. Isso coloca o atacante
dentro do caminho, dando-lhe a capacidade de observar ou descartar todos
os pacotes subsequentes.

Este estilo de ataque depende do atacante usar um caminho que tenha
características aproximadamente iguais ao caminho direto entre
endpoints. O ataque é mais confiável se relativamente poucos pacotes forem
enviados ou se a perda de pacotes coincidir com o ataque tentado.

Um pacote não-sondado recebido no caminho original que aumente o
número máximo de pacotes recebidos fará com que o endpoint se mova de volta
para esse caminho. Evocar pacotes nesse caminho aumenta a
probabilidade de que o ataque falhe. Portanto, a mitigação deste
ataque depende da ativação da troca de pacotes.

Em resposta a uma migração aparente, endpoints DEVE validar o
caminho ativo anteriormente usando um frame PATH_CHALLENGE. Isso induz
o envio de novos pacotes nesse caminho. Se o caminho não for mais
viável, a tentativa de validação irá expirar e falhar; se o caminho for
viável, mas não mais desejado, a validação terá sucesso, mas só
resultará em pacotes de sondagem sendo enviados no caminho.

Um endpoint que recebe um PATH_CHALLENGE em um caminho ativo DEVE
enviar um pacote de não-sondagem em resposta. Se o pacote de não-sondagem
chegar antes de qualquer cópia feita por um atacante, isso resultará na
conexão sendo migrada de volta para o caminho original. Qualquer migração
subsequente para outro caminho reinicia todo este processo.

Esta defesa não é perfeita, mas isso não é considerado um problema
sério. Se o caminho via o ataque for confiavelmente mais rápido que o
caminho original, apesar de múltiplas tentativas de usar aquele caminho
original, não é possível distinguir entre um ataque e uma melhoria
de roteamento.

Um endpoint poderia também usar heurísticas para melhorar a detecção deste
estilo de ataque. Por exemplo, o reencaminhamento NAT é improvável se
os pacotes foram recebidos recentemente no caminho antigo; de forma semelhante, o reencaminhamento
é raro em caminhos IPv6. Endpoints podem também procurar por pacotes duplicados.
Por outro lado, uma mudança de ID de conexão é mais provável de indicar
uma migração intencional ao invés de um ataque.

Detecção de Perda e Controle de Congestionamento
```````````````````````````````````````````````````

A capacidade disponível no novo caminho pode não ser a mesma que a
velha. Pacotes enviados no caminho antigo NÃO DEVEM contribuir para
controle de congestionamento ou estimativa de RTT para o novo caminho.

Ao confirmar a posse do peer de seu novo endereço, um endpoint DEVE
imediatamente redefinir o controlador de congestionamento e estimador de round-trip time
para o novo caminho para valores iniciais (ver Apêndices A.3 e B.3 de
[QUIC-RECOVERY]), a menos que a única mudança no endereço do peer
seja seu número de porta. Porque mudanças somente de porta são comumente o
resultado de reencaminhamento NAT ou outra atividade de middlebox, o endpoint PODE
em vez disso, reter seu estado de controle de congestionamento e estimativa de round-trip neste
caso em vez de reverter para valores iniciais. Em casos onde o
estado de controle de congestionamento retido de um caminho antigo é usado em um
novo caminho com características substancialmente diferentes, um remetente poderia
transmitir de forma muito agressiva até que o controlador de congestionamento e o
estimador de RTT tenham se adaptado. Geralmente, as implementações são
recomendadas a serem cautelosas ao usar valores anteriores em um novo caminho.

Pode haver reordenação aparente no receptor quando um endpoint
envia dados e sondas de/para múltiplos endereços durante o período de
migração, uma vez que os dois caminhos resultantes poderiam ter diferentes
tempos de round-trip. Um receptor de pacotes em múltiplos caminhos ainda
enviará frames ACK cobrindo todos os pacotes recebidos.

Enquanto múltiplos caminhos podem ser usados durante a migração de conexões, um
único contexto de controle de congestionamento e um único contexto de
recuperação de perda (como descrito em [QUIC-RECOVERY]) podem ser
suficientes. Por exemplo, um endpoint pode atrasar a mudança para um novo
contexto de controle de congestionamento até que seja confirmado que um caminho antigo
não é mais necessário (tal como o caso descrito na Seção 9.3.3).

Um remetente pode fazer exceções para pacotes de sondagem para que sua perda
de detecção seja independente e não cause indevidamente o controlador de
congestionamento reduzir sua taxa de envio. Um endpoint pode definir um
temporizador separado quando um PATH_CHALLENGE é enviado, que é cancelado se
o correspondente PATH_RESPONSE for recebido. Se o temporizador disparar
antes do PATH_RESPONSE ser recebido, o endpoint pode enviar um novo
PATH_CHALLENGE e reiniciar o temporizador por um período de tempo
mais longo. Este temporizador DEVE ser definido conforme descrito na Seção 6.2.1
de [QUIC-RECOVERY] e NÃO DEVE ser mais agressivo.

Implicações de Privacidade da Migração de Conexão
`````````````````````````````````````````````````

Usar um ID de conexão estável em múltiplos caminhos de rede permitiria a
um observador passivo correlacionar atividade entre aqueles caminhos. Um
endpoint que se move entre redes pode não desejar ter sua
atividade correlacionada por qualquer entidade que não seu peer, então
diferentes IDs de conexão são usados ao enviar de diferentes endereços locais,
como discutido na Seção 5.1. Para isso ser eficaz, endpoints
precisam assegurar que IDs de conexão que fornecem não possam ser vinculados por
qualquer outra entidade.

A qualquer momento, endpoints PODEM mudar o ID de Conexão de Destino que
transmitem com para um valor que não foi usado em outro caminho.

Um endpoint NÃO DEVE reutilizar um ID de conexão ao enviar de
mais de um endereço local - por exemplo, ao iniciar migração
de conexão conforme descrito na Seção 9.2 ou ao sondar um novo caminho
de rede conforme descrito na Seção 9.1.

Similarmente, um endpoint NÃO DEVE reutilizar um ID de conexão ao enviar para
mais de um endereço de destino. Devido a mudanças de rede fora
do controle de seu peer, um endpoint pode receber pacotes de um novo
endereço de origem com o mesmo valor de campo ID de Conexão de
Destino, caso em que ele PODE continuar usando o ID de conexão
atual com o novo endereço remoto enquanto ainda envia do mesmo
endereço local.

Esses requisitos sobre a reutilização de ID de conexão aplicam-se apenas ao
envio de pacotes, uma vez que mudanças não intencionais no caminho sem uma mudança
em ID de conexão são possíveis. Por exemplo, após um período de
inatividade de rede, uma reatribuição NAT pode fazer com que pacotes sejam enviados em um
novo caminho quando o cliente retoma o envio. Um endpoint responde a
um tal evento conforme descrito na Seção 9.3.

Usar diferentes IDs de conexão para pacotes enviados em ambas direções em
cada novo caminho de rede elimina o uso do ID de conexão
para vincular pacotes da mesma conexão em caminhos de rede
diferentes. A proteção do cabeçalho garante que números de pacotes
não possam ser usados para correlacionar atividade. Isso não impede
outros atributos de pacotes, como temporização e tamanho, de serem usados
para correlacionar atividade.

Um endpoint NÃO DEVE iniciar migração com um peer que solicitou
um ID de conexão de comprimento zero, porque o tráfego sobre o novo
caminho pode ser trivialmente associável ao tráfego sobre o antigo. Se o
servidor for capaz de associar pacotes com um ID de conexão de
comprimento zero à conexão correta, isso significa que o servidor
está usando outras informações para desmultiplexar pacotes. Por
exemplo, um servidor pode fornecer um endereço único a cada cliente -
por exemplo, usando serviços alternativos HTTP [ALTSVC]. Informações
que podem permitir roteamento correto de pacotes em múltiplos caminhos de
rede também permitirão que a atividade nesses
caminhos seja vinculada por entidades além do peer.

Um cliente pode desejar reduzir a associabilidade mudando para um
novo ID de conexão, porta UDP de origem ou endereço IP (ver [RFC8981])
ao enviar tráfego após um período de inatividade. Mudar o endereço
do qual ele envia pacotes ao mesmo tempo pode causar o servidor
detectar uma migração de conexão. Isso garante que os mecanismos
que suportam a migração sejam exercitados, mesmo para clientes que
não experimentam reencaminhamentos NAT ou migrações genuínas.
Mudar o endereço pode fazer com que um peer redefina seu estado de controle de
congestionamento (ver Seção 9.4), por isso os endereços DEVEM ser
mudados apenas com pouca frequência.

Um endpoint que esgota IDs de conexão disponíveis não pode sondar novos
caminhos ou iniciar migração, nem pode responder a sondas ou tentativas
de seu peer de migrar. Para garantir que a migração seja possível e
pacotes enviados em caminhos diferentes não possam ser correlacionados, endpoints
DEVEM fornecer novos IDs de conexão antes que peers migrem; ver
Seção 5.1.1. Se um peer pode ter esgotado IDs de conexão
disponíveis, um endpoint migrante poderia incluir um frame NEW_CONNECTION_ID em
todos os pacotes enviados em um novo caminho de rede.

Endereço Preferido do Servidor
````````````````````````````````

O QUIC permite que servidores aceitem conexões em um endereço IP
e tentem transferir essas conexões para um endereço mais preferido
pouco depois do handshake. Isso é particularmente útil quando
clientes inicialmente se conectam a um endereço compartilhado por múltiplos servidores,
mas prefeririam usar um endereço unicast para garantir a
estabilidade da conexão. Esta seção descreve o protocolo para
migrar uma conexão para um endereço preferido do servidor.

Migrar uma conexão para um novo endereço de servidor no meio da
conexão não é suportado pela versão do QUIC especificada neste documento. Se
um cliente receber pacotes de um novo endereço de servidor quando o cliente
não tiver iniciado uma migração para esse endereço, o cliente DEVE descartar
estes pacotes.

Comunicando um Endereço Preferido
````````````````````````````````````````

Um servidor transmite um endereço preferido ao incluir o
parâmetro de transporte preferred_address no handshake TLS.

Servidores PODEM comunicar um endereço preferido de cada família de
endereços (IPv4 e IPv6) para permitir que clientes escolham o mais adequado para sua
rede conectada.

Depois que o handshake é confirmado, o cliente DEVE selecionar um dos
dois endereços fornecidos pelo servidor e iniciar a validação de caminho
(ver Seção 8.2). Um cliente constrói pacotes usando qualquer
ID de conexão ativo anteriormente não usado, retirado tanto do parâmetro de transporte
preferred_address quanto de um frame NEW_CONNECTION_ID.

Assim que a validação do caminho for bem-sucedida, o cliente deve começar a
enviar todos os pacotes futuros para o novo endereço do servidor usando
o novo ID de conexão e descontinuar o uso do antigo endereço do servidor.
Se a validação do caminho falhar, o cliente DEVE continuar a
enviar todos os pacotes futuros para o endereço IP original do servidor.

Migração para um Endereço Preferido
``````````````````````````````````````

Um cliente que migra para um endereço preferido DEVE validar o
endereço que escolhe antes de migrar; ver Seção 21.5.3.

Um servidor pode receber um pacote endereçado ao seu endereço IP preferido
a qualquer momento após aceitar uma conexão. Se este pacote contiver um
frame PATH_CHALLENGE, o servidor envia um pacote contendo um
frame PATH_RESPONSE conforme a Seção 8.2. O servidor DEVE enviar pacotes não-
de sondagem de seu endereço original até que ele receba um
pacote de não-sondagem do cliente em seu endereço preferido e até que o
servidor tenha validado o novo caminho.

O servidor DEVE fazer sondagem no caminho em direção ao cliente a partir de seu
endereço preferido. Isso ajuda a proteger contra migrações espúrias
iniciadas por um atacante.

Assim que o servidor tenha completado sua validação de caminho e recebido um
pacote de não-sondagem com um novo maior número de pacote em seu endereço
preferido, o servidor começa a enviar pacotes de não-sondagem para o cliente
exclusivamente de seu endereço IP preferido. O servidor DEVE descartar
pacotes mais novos para esta conexão que são recebidos no velho endereço IP.
O servidor PODE continuar a processar pacotes atrasados que são
recebidos no velho endereço IP.

Os endereços que um servidor fornece no parâmetro de transporte preferred_address
são válidos apenas para a conexão na qual foram fornecidos. Um cliente
NÃO DEVE usar esses para outras conexões,
incluindo conexões que são retomadas da conexão atual.

Interação de Migração de Cliente e Endereço Preferido
``````````````````````````````````````````````````````````

Um cliente pode precisar realizar uma migração de conexão antes de
ter migrado para o endereço preferido do servidor. Nesse caso, o cliente
DEVE realizar validação de caminho tanto para o endereço de servidor original quanto
preferido a partir do novo endereço do cliente simultaneamente.

Se a validação do caminho do endereço preferido do servidor tiver sucesso, o
cliente DEVE abandonar a validação do endereço original e migrar para
usar o endereço preferido do servidor. Se a validação do caminho
do endereço preferido do servidor falhar, mas a validação do
endereço original do servidor tiver sucesso, o cliente PODE
migrar para seu novo endereço e continuar enviando para o endereço
original do servidor.

Se pacotes recebidos no endereço preferido do servidor tiverem
um endereço de origem diferente do observado no cliente durante o
handshake, o servidor DEVE se proteger contra possíveis ataques conforme
descritos nas Seções 9.3.1 e 9.3.2. Além de migração
simultânea intencional, isso pode ocorrer porque a
rede de acesso do cliente usou uma diferente vinculação NAT para o
endereço preferido do servidor.

Servidores DEVEM iniciar validação de caminho para o novo endereço
do cliente ao receber um pacote de sonda de um endereço diferente; ver
Seção 8.

Um cliente que migra para um novo endereço DEVE usar um endereço preferido
da mesma família de endereços para o servidor.

O ID de conexão fornecido no parâmetro de transporte preferred_address
não é específico para os endereços que são fornecidos. Este
ID de conexão é fornecido para garantir que o cliente tenha um ID
de conexão disponível para migração, mas o cliente PODE usar este ID
de conexão em qualquer caminho.

Uso do Rótulo de Fluxo IPv6 e Migração
````````````````````````````````````````````

QUIC recomenda que endpoints que enviam dados usando IPv6 DEVEM aplicar um rótulo de fluxo IPv6
em conformidade com [RFC-6437](https://www.rfc-editor.org/rfc/rfc6437.html), a menos que a API local não permita
definir rótulos de fluxo IPv6.

Infelizmente, a API Java não permite definir rótulos de fluxo IPv6.


### Considerações de Segurança

O seguinte é copiado do QUIC [RFC-9000](https://www.rfc-editor.org/rfc/rfc9000.html).
Para cada seção, revise e edite.

O objetivo do QUIC é fornecer uma conexão de transporte segura.
A Seção 21.1 fornece uma visão geral dessas propriedades; subsequentes
seções discutem restrições e advertências sobre essas propriedades,
incluindo descrições de ataques conhecidos e contramedidas.

Visão Geral das Propriedades de Segurança
``````````````````````````````````````````````

Uma análise completa de segurança do QUIC está fora do escopo deste
documento.  Esta seção fornece uma descrição informal das
desejadas propriedades de segurança como uma ajuda para os implementadores e para
orientar a análise do protocolo.

O QUIC assume o modelo de ameaça descrito em [SEC-CONS] e fornece
proteções contra muitos dos ataques que surgem desse modelo.

Para este propósito, os ataques são divididos em ataques passivos e ativos.
Atacantes passivos têm a capacidade de ler pacotes da
rede, enquanto os atacantes ativos também têm a capacidade de escrever
pacotes na rede.  No entanto, um ataque passivo poderia envolver um
atacante com a capacidade de causar uma mudança de roteamento ou
modificação no caminho tomado por pacotes que compõem uma conexão.

Os atacantes são adicionalmente categorizados como atacantes na linha ou
fora da linha.  Um atacante na linha pode ler, modificar ou remover
qualquer pacote que observe de modo que o pacote não alcance
mais seu destino, enquanto um atacante fora da linha observa os pacotes
mas não pode impedir que o pacote original chegue ao seu destino
pretendido.  Ambos os tipos de atacantes também podem transmitir pacotes
arbitrários.  Esta definição difere da Seção 3.5 de
[SEC-CONS] em que um atacante fora da linha é capaz de
observar pacotes.

As propriedades do handshake, pacotes protegidos e
migração de conexão são consideradas separadamente.

Handshake
``````````````````````````````````````````````

O handshake QUIC incorpora o handshake TLS 1.3 e herda
as propriedades criptográficas descritas no Apêndice E.1 de [TLS13].
Muitas das propriedades de segurança do QUIC dependem do handshake TLS
proporcionando essas propriedades.  Qualquer ataque ao handshake TLS poderia
afetar o QUIC.

Qualquer ataque ao handshake TLS que comprometa o sigilo ou a
unicidade das chaves de sessão, ou a autenticação dos
peers participantes, afeta outras garantias de segurança fornecidas por
QUIC que dependem dessas chaves.  Por exemplo, migração (Seção 9)
depende da eficácia das proteções de confidencialidade, tanto para a
negociação de chaves usando o handshake TLS e para a
proteção de pacotes QUIC, para evitar a vinculação de caminhos
de rede.

Um ataque à integridade do handshake TLS pode permitir que um
atacante afete a seleção do protocolo de aplicação ou
versão QUIC.

Além das propriedades fornecidas pelo TLS, o handshake QUIC
oferece alguma defesa contra ataques de DoS ao handshake.

Anti-Amplificação
``````````````````````````````````````````````

Validação de endereço (Seção 8) é usada para verificar que uma
entidade que reivindica um determinado endereço é capaz de receber
pacotes naquele endereço.  Validação de endereço limita o
alvo de ataque de amplificação a endereços para os quais um atacante pode
observar pacotes.

Antes da validação de endereço, endpoints são limitados no que
podem enviar.  Endpoints não podem enviar dados em direção a um endereço não validado
em excesso de três vezes os dados recebidos daquele endereço.

Nota: O limite de anti-amplificação só se aplica quando um
endpoint responde a pacotes recebidos de um endereço não validado.
O limite de anti-amplificação não se aplica a
clientes ao estabelecer uma nova conexão ou ao iniciar
migração de conexão.

DoS no Lado do Servidor
``````````````````````````````````````````````

Computar o primeiro voo do servidor para um handshake completo é
potencialmente caro
